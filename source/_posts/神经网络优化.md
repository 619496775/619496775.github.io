---
title: 神经网络优化
date: 2019-11-08 21:17:29
tags:
---
## 1

![](1.png)
![](2.png)

```python
#coding:utf-8
#预测多或预测少的影响一样
#0导入模块，生成数据集
import tensorflow as tf
import numpy as np
BATCH_SIZE = 8
SEED = 23455

rdm = np.random.RandomState(SEED)
X = rdm.rand(32,2)
Y_ = [[x1+x2+(rdm.rand()/10.0-0.05)] for (x1,x2) in X]

#1定义神经网络的输入、参数和输出，定义前向传播过程。
x = tf.placeholder(tf.float32,shape=(None,2))
y_ = tf.placeholder(tf.float32,shape=(None,1))
w1 = tf.Variable(tf.random_normal([2,1],stddev=1,seed=1))
y = tf.matmul(x,w1)

#2定义损失函数及反向传播方法。
#定义损失函数为MSE，反向传播方法为梯度下降。
loss_mse = tf.reduce_mean(tf.square(y_-y))
train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss_mse)

#生成会话，训练STEPS轮
with tf.Session() as sess:
init_op = tf.global_variables_initializer()
sess.run(init_op)
STEPS = 20000
for i in range(STEPS):
start = (i*BATCH_SIZE)%32
end = (i*BATCH_SIZE)%32 + BATCH_SIZE
sess.run(train_step,feed_dict={x:X[start:end],y_:Y_[start:end]})
if i %500 == 0:
print "After %d training steps, w1 is"%(i)
print  sess.run(w1)
print  "Final w1 is:\n",sess.run(w1)
#在本代码#2中尝试其他反向传播方法，看对收敛速度的影响，把体会写到笔记中
```
运行结果如下:

![](3.png)

由上述代码可知，本例中神经网络预测模型为 y = w1*x1 + w2*x2，损失函数采用均方误差。通过使 损失函数值(loss)不断降低，神经网络模型得到最终参数 w1=0.98，w2=1.02，销量预测结果为 y = 0.98*x1 + 1.02*x2。由于在生成数据集时，标准答案为 y = x1 + x2，因此，销量预测结果和标准 答案已非常接近，说明该神经网络预测酸奶日销量正确。
**自定义损失函数:根据问题的实际情况，定制合理的损失函数。**

例如: 对于预测酸奶日销量问题，如果预测销量大于实际销量则会损失成本;如果预测销量小于实际销量则 会损失利润。在实际生活中，往往制造一盒酸奶的成本和销售一盒酸奶的利润是不等价的。因此，需 要使用符合该问题的自定义损失函数。
自定义损失函数为:loss = ∑𝑛𝑓(y_, y)
其中，损失定义成分段函数:
```
f(y_,y)=𝑃𝑅𝑂𝐹𝐼𝑇∗(𝑦_−𝑦) 𝑦<𝑦_ 
𝐶𝑂𝑆𝑇∗(𝑦−𝑦_)  𝑦>=𝑦_
```
损失函数表示，若预测结果 y 小于标准答案 y_，损失函数为利润乘以预测结果 y 与标准答案 y_之差; 若预测结果 y 大于标准答案 y_，损失函数为成本乘以预测结果 y 与标准答案 y_之差。
用 Tensorflow 函数表示为:
loss = tf.reduce_sum(tf.where(tf.greater(y,y_),COST(y-y_),PROFIT(y_-y)))
1 若酸奶成本为 1 元，酸奶销售利润为 9 元，则制造成本小于酸奶利润，因此希望预测的结果 y 多
一些。采用上述的自定义损失函数，训练神经网络模型。
代码如下:
```python
#coding:utf-8
#成本9元，利润1元
#预测多或预测少的影响一样
#0导入模块，生成数据集
import tensorflow as tf
import numpy as np
BATCH_SIZE = 8
SEED = 23455
COST = 9
PROFIT = 1

rdm = np.random.RandomState(SEED)
X = rdm.rand(32,2)
Y_ = [[x1+x2+(rdm.rand()/10.0-0.05)] for (x1,x2) in X]

#1定义神经网络的输入、参数和输出，定义前向传播过程。
x = tf.placeholder(tf.float32,shape=(None,2))
y_ = tf.placeholder(tf.float32,shape=(None,1))
w1 = tf.Variable(tf.random_normal([2,1],stddev=1,seed=1))
y = tf.matmul(x,w1)

#2定义损失函数及反向传播方法。
#定义损失函数使得预测少了的损失大，于是应该向便多的方向预测。反向传播方法为梯度下降。
loss_mse = tf.reduce_sum(tf.where(tf.greater(y,y_),(y-y_)*COST,(y_-y)*PROFIT))
train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss_mse)

#生成会话，训练STEPS轮
with tf.Session() as sess:
init_op = tf.global_variables_initializer()
sess.run(init_op)
STEPS = 20000
for i in range(STEPS):
start = (i*BATCH_SIZE)%32
end = (i*BATCH_SIZE)%32 + BATCH_SIZE
sess.run(train_step,feed_dict={x:X[start:end],y_:Y_[start:end]})
if i %500 == 0:
print "After %d training steps, w1 is"%(i)
print  sess.run(w1)
print  "Final w1 is:\n",sess.run(w1)
#在本代码#2中尝试其他反向传播方法，看对收敛速度的影响，把体会写到笔记中

```
运行结果如下:

![](4.png)

**交叉熵(Cross Entropy):表示两个概率分布之间的距离。交叉熵越大，两个概率分布距离越远，两 个概率分布越相异;交叉熵越小，两个概率分布距离越近，两个概率分布越相似。 交叉熵计算公式:𝐇(𝐲_ , 𝐲) = −∑𝐲_ ∗ 𝒍𝒐𝒈 𝒚
用 Tensorflow 函数表示为**
ce= -tf.reduce_mean(y_* tf.log(tf.clip_by_value(y, 1e-12, 1.0)))

![](4.png)

## 2
**学习率 learning_rate:表示了每次参数更新的幅度大小。学习率过大，会导致待优化的参数在最 小值附近波动，不收敛;学习率过小，会导致待优化的参数收敛缓慢。 在训练过程中，参数的更新向着损失函数梯度下降的方向。
参数的更新公式为:
𝒘𝒏+𝟏 = 𝒘𝒏 − 𝒍𝒆𝒂𝒓𝒏𝒊𝒏𝒈_𝒓𝒂𝒕𝒆𝛁**

```python
#coding:utf-8
#设损失函数 loss=(w+1)^2,令w初值是常数5。反向传播就是求最优w，即求最小loss对应的w值
import tensorflow as tf
#定义待优化参数w初值5
w = tf.Variable(tf.constant(5,dtype=tf.float32))
#定义损失函数loss
loss = tf.square(w+1)
#定义反向传播方法
train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)
#生成会话，训练40轮
with tf.Session() as sess:
init_op = tf.global_variables_initializer()
sess.run(init_op)
for i in range(40):
sess.run(train_step)
w_val = sess.run(w)
loss_val = sess.run(loss)
print "After %s steps: w is %f.   loss is %f" % (i, w_val,loss_val)
```
运行结果如下:
![](5.png)
由结果可知，随着损失函数值的减小，w 无限趋近于-1，模型计算推测出最优参数 w = -1。
**学习率的设置 学习率过大，会导致待优化的参数在最小值附近波动，不收敛;学习率过小，会导致待优化的参数收 敛缓慢。**

**指数衰减学习率:学习率随着训练轮数变化而动态更新**
```python
#coding:utf-8
#设损失函数 loss=(w+1)^2,令w初值是常数10。反向传播就是求最优w，即求最小loss对应的w值
#使用指数衰减的学习率，在迭代初期得到较高的下降速度，可以在较小的训练轮数下取的更优收敛度
import tensorflow as tf

LEARNING_RATE_BASE = 0.1 #最初学习率
LEARNING_RATE_DECAY = 0.99 #学习率衰减率
LEARNING_RATE_STEP = 1 #喂入多少轮BATCH_SIZE后，更新一次学习率，一般设为：总样本数/BATCH_SIZE

#运行了几轮BATCH_SIZE的计数器，初值给0，设为不被训练
global_step = tf.Variable(0,trainable=False)
#定义指数下降学习率
learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE,global_step,LEARNING_RATE_STEP,LEARNING_RATE_DECAY,
staircase=True)
#定义待优化参数，初值给10
w = tf.Variable(tf.constant(5,dtype=tf.float32))
#定义损失函数loss
loss = tf.square(w+1)
#定义反向传播方法
train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)
#生成会话，训练40轮
with tf.Session() as sess:
init_op = tf.global_variables_initializer()
sess.run(init_op)
for i in range(40):
sess.run(train_step)
learning_rate_val = sess.run(learning_rate)
global_step_val = sess.run(global_step)
w_val = sess.run(w)
loss_val = sess.run(loss)
print "After %s steps: global_step is %f , learning rate is %f, w is %f.   loss is %f" % (i,global_step_val,learning_rate_val, w_val,loss_val)
```
运行结果如下:
![](6.png)
由结果可以看出，随着训练轮数增加学习率在不断减小。

## 3
滑动平均:记录了一段时间内模型中所有参数 w 和 b 各自的平均值。利用滑动平均值可以增强模 型的泛化能力。
滑动平均值(影子)计算公式:
影子 = 衰减率 * 影子 +(1 - 衰减率)* 参数
其中，衰减率 = 𝐦𝐢𝐧 {𝑴𝑶𝑽𝑰𝑵𝑮𝑨𝑽𝑬𝑹𝑨𝑮𝑬𝑫𝑬𝑪𝑨𝒀 , 𝟏+轮数 /10+轮数}，影子初值=参数初值
√用 Tesnsorflow 函数表示为:
√ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY，global_step) 其中，MOVING_AVERAGE_DECAY 表示滑动平均衰减率，一般会赋接近 1 的值，global_step 表示当前 训练了多少轮。
√ema_op = ema.apply(tf.trainable_variables()) 其中，ema.apply()函数实现对括号内参数求滑动平均，tf.trainable_variables()函数实现把所有 待训练参数汇总为列表。
√with tf.control_dependencies([train_step, ema_op]):
train_op = tf.no_op(name='train')
其中，该函数实现将滑动平均和训练过程同步运行。
查看模型中参数的平均值，可以用 ema.average()函数。
例如:
在神经网络模型中，将 MOVING_AVERAGE_DECAY 设置为 0.99，参数 w1 设置为 0，w1 的滑动平均值设 置为 0。
1开始时，轮数 global_step 设置为 0，参数 w1 更新为 1，则 w1 的滑动平均值为:
w1 滑动平均值=min(0.99,1/10)*0+(1– min(0.99,1/10)*1 = 0.9
3 当轮数 global_step 设置为 100 时，参数 w1 更新为 10，以下代码 global_step 保持为 100，每
次执行滑动平均操作影子值更新，则滑动平均值变为:
w1 滑动平均值=min(0.99,101/110)*0.9+(1– min(0.99,101/110)*10 = 0.826+0.818=1.644 3再次运行，参数 w1 更新为 1.644，则滑动平均值变为:
w1 滑动平均值=min(0.99,101/110)*1.644+(1– min(0.99,101/110)*10 = 2.328 4再次运行，参数 w1 更新为 2.328，则滑动平均值:
w1 滑动平均值=2.956
代码如下:
```python
#coding:utf-8
import tensorflow as tf

#1. 定义变量及滑动平均类
#定义一个32位浮点变量，初始值位0.0  这个代码就是不断更新w1参数，优化w1参数滑动平均做了一个w1的影子
w1 = tf.Variable(0,dtype=tf.float32)
#定义num_updates(NN的迭代轮数)，初始值位0，不可被优化（训练），这个参数不训练
global_step = tf.Variable(0,trainable=False)
#实例化滑动平均类，给删减率为0。99，当前轮数global_step
MOVING_AVERAGE_DECAY = 0.99
ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY,global_step)
#ema.apply后的括号里是更新列表，每次运行sess.run(ema_op)时，对更新列表中的元素求滑动平均值。
#在实际应用中会使用tf.trainble_variable()自动将所有待训练的参数汇总为列表
#ema_op = em.apply([w1])
ema_op = ema.apply(tf.trainable_variables())

#2. 查看不同迭代中变量取值的变化。
with tf.Session() as sess:
#初始化
init_op = tf.global_variables_initializer()
sess.run(init_op)
#用ema.average(w1)获取w1滑动平均值  （要运行多个节点，作为列表中的元素列出，写在sess.run中）
print sess.run([w1,ema.average(w1)])

# 参数w1的值赋为1
sess.run(tf.assign(w1, 1))
sess.run(ema_op)
print sess.run([w1,ema.average(w1)])

#更新step和w1的值，模拟出100轮迭代后，参数w1变化为10
sess.run(tf.assign(global_step,100))
sess.run(tf.assign(w1,10))
sess.run(ema_op)
print sess.run([w1,ema.average(w1)])

# 每次sess.run会更新一次w1的滑动平均值
sess.run(ema_op)
print sess.run([w1, ema.average(w1)])

sess.run(ema_op)
print sess.run([w1, ema.average(w1)])

sess.run(ema_op)
print sess.run([w1,ema.average(w1)])

sess.run(ema_op)
print sess.run([w1, ema.average(w1)])

sess.run(ema_op)
print sess.run([w1, ema.average(w1)])

sess.run(ema_op)
print sess.run([w1, ema.average(w1)])

#更改MOVING_AVERAGE_DECAY 为 0.1 看影子追随速度

```
运行程序，结果如下:
![](7.png)

从运行结果可知，最初参数 w1 和滑动平均值都是 0;参数 w1 设定为 1 后，滑动平均值变为 0.9; 当迭代轮数更新为 100 轮时，参数 w1 更新为 10 后，滑动平均值变为 1.644。随后每执行一次，参数 w1 的滑动平均值都向参数 w1 靠近。可见，滑动平均追随参数的变化而变化。

## 4
√过拟合:神经网络模型在训练数据集上的准确率较高，在新的数据进行预测或分类时准确率较 低，说明模型的泛化能力差。
√正则化:在损失函数中给每个参数 w 加上权重，引入模型复杂度指标，从而抑制模型噪声，减小 过拟合。
使用正则化后，损失函数 loss 变为两项之和:
`loss = loss(y 与 y_) + REGULARIZER*loss(w) `其中，第一项是预测结果与标准答案之间的差距，如之前讲过的交叉熵、均方误差等;第二项是正则
化计算结果。
√正则化计算方法:
1 L1 正则化: 𝒍𝒐𝒔𝒔𝑳𝟏 = ∑𝒊|𝒘𝒊|
用 Tesnsorflow 函数表示:loss(w) = tf.contrib.layers.l1_regularizer(REGULARIZER)(w) 2 L2 正则化: 𝒍𝒐𝒔𝒔𝑳𝟐 = ∑𝒊|𝒘𝒊|𝟐
用 Tesnsorflow 函数表示:loss(w) = tf.contrib.layers.l2_regularizer(REGULARIZER)(w) √用 Tesnsorflow 函数实现正则化:
tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(regularizer)(w) loss = cem + tf.add_n(tf.get_collection('losses'))

√matplotlib 模块:Python 中的可视化工具模块，实现函数可视化 终端安装指令:sudo pip install matplotlib
√函数 plt.scatter():利用指定颜色实现点(x,y)的可视化 plt.scatter (x 坐标, y 坐标, c=”颜色”)
plt.show()
√收集规定区域内所有的网格坐标点:
xx, yy = np.mgrid[起:止:步长, 起:止:步长] #找到规定区域以步长为分辨率的行列网格坐标点 grid = np.c_[xx.ravel(), yy.ravel()] #收集规定区域内所有的网格坐标点 √plt.contour()函数:告知 x、y 坐标和各点高度，用 levels 指定高度的点描上颜色 plt.contour (x 轴坐标值, y 轴坐标值, 该点的高度, levels=[等高线的高度])
plt.show()

代码如下：
```python
# coding:utf-8
# 0 导入模块，生成模拟数据集
import tensorflow as tf
import numpy as np

import matplotlib.pyplot as plt
BATCH_SIZE = 30
seed = 2
# 基于seed产生随机数
rdm = np.random.RandomState(seed)
# 随机数返回300行2列的矩阵，表示300组坐标点x0,x1）作为输入数据集
X = rdm.randn(300,2)
# 从X这个300行2列的矩阵中取出一行，判断如果两个坐标的平方和小于2，给Y赋值1，其余赋值0
# 作为输入数据集的标签（正确答案）
Y_ = [int(x0*x0 + x1*x1 <2) for (x0,x1) in X]
# 遍历Y中的每个元素，1赋值'red'其余赋值'blue'，这样可视化显示时人可以直观区分
Y_c = [['red' if y else 'blue'] for y in Y_]
# 对数据集X和标签Y进行shape整理，第一个元素为-1表示，随第二个参数计算得到，第二个元素表示多少列，把X整理为n行2列，把Y整理为n行1列
X = np.vstack(X).reshape(-1,2)
Y_ = np.vstack(Y_).reshape(-1,1)
print X
print Y_
print Y_c
# 用plt.scatter画出数据集X各行中第0列元素和第一列元素的点即各行的（x0，x1），用各行Y_c对应的值表示颜色（c是color的缩写）
plt.scatter(X[:,0],X[:,1],c=np.squeeze(Y_c))
plt.show()

#定义神经网络的输入、参数和输出，定义前向传播过程
def get_weight(shape,regularizer):
w = tf.Variable(tf.random_normal(shape),dtype=tf.float32)
tf.add_to_collection('losses',tf.contrib.layers.l2_regularizer(regularizer)(w))
return w

def get_bias(shape):
b = tf.Variable(tf.constant(0.01,shape=shape))
return b

x = tf.placeholder(tf.float32,shape=(None,2))
y_ = tf.placeholder(tf.float32,shape=(None,1))

w1 = get_weight([2,11],0.01)
b1 = get_bias([11])
y1 = tf.nn.relu(tf.matmul(x,w1)+b1)

w2 = get_weight([11,1],0.01)
b2 = get_bias([1])
y = tf.matmul(y1,w2)+b2 #输出层不过激活

#定义损失函数
loss_mse = tf.reduce_mean(tf.square(y-y_))        #均方误差的损失函数
loss_total = loss_mse + tf.add_n(tf.get_collection('losses'))   #均方误差的损失函数加上每一个正则化w的损失

#定义反向传播方法：不含正则化
train_step = tf.train.AdamOptimizer(0.0001).minimize(loss_mse)

with tf.Session() as sess:
init_op = tf.global_variables_initializer()
sess.run(init_op)
STEPS = 40000
for i in range(STEPS):
start = (i*BATCH_SIZE)%300
end = start+BATCH_SIZE
sess.run(train_step,feed_dict={x:X[start:end],y_:Y_[start:end]})
if i % 2000 ==0:
loss_mse_v = sess.run(loss_mse,feed_dict={x:X,y_:Y_})
print ("After %d steps, loss is %f"%(i,loss_mse_v))
# xx在 -3到3之间以步长为0。01，yy在 -3到3之间以步长0。01，生成二维网格坐标点
xx,yy = np.mgrid[-3:3:0.01,-3:3:0.01]
#将xx，yy拉直，并合并成一个2列的矩阵，得到一个网格坐标点的集合
grid = np.c_[xx.ravel(),yy.ravel()]
#将网格坐标点喂入神经网络，probs为输出
probs = sess.run(y,feed_dict={x:grid})
#probs的shape调整成xx的样子
probs = probs.reshape(xx.shape)
print "w1:\n",sess.run(w1)
print "b1:\n",sess.run(b1)
print "w2:\n",sess.run(w2)
print "b2:\n",sess.run(b2)

plt.scatter(X[:,0],X[:,1],c=np.squeeze(Y_c))
plt.contour(xx,yy,probs,levels=[0.5])
plt.show()


#定义反向传播方法：包含正则化
train_step = tf.train.AdamOptimizer(0.0001).minimize(loss_total)

with tf.Session() as sess:
init_op = tf.global_variables_initializer()
sess.run(init_op)
STEPS = 40000
for i in range(STEPS):
start = (i*BATCH_SIZE) % 300
end = start+BATCH_SIZE
sess.run(train_step,feed_dict={x:X[start:end],y_:Y_[start:end]})
if i % 2000 ==0:
loss_v = sess.run(loss_total,feed_dict={x:X,y_:Y_})
print ("After %d steps, loss is: %f"%(i,loss_v))

xx,yy = np.mgrid[-3:3:0.01,-3:3:0.01]
grid = np.c_[xx.ravel(),yy.ravel()]
probs = sess.run(y,feed_dict={x:grid})
probs = probs.reshape(xx.shape)
print "w1:\n", sess.run(w1)
print "b1:\n", sess.run(b1)
print "w2:\n", sess.run(w2)
print "b2:\n", sess.run(b2)
plt.scatter(X[:,0],X[:,1],c=np.squeeze(Y_c))
plt.contour(xx,yy,probs,levels=[0.5])
plt.show()

```
执行代码，效果如下:
首先，数据集实现可视化，x0 + x1 < 2 的点显示红色， x0 + x1 ≥2 的点显示蓝色，如图所示:
![](8.png)
接着，执行无正则化的训练过程，把红色的点和蓝色的点分开，生成曲线如下图所示:
![](9.png)
最后，执行有正则化的训练过程，把红色的点和蓝色的点分开，生成曲线如下图所示:
![](10.png)
对比无正则化与有正则化模型的训练结果，可看出有正则化模型的拟合曲线平滑，模型具有更好的泛 化能力。

[参考文献：中国大学mooc人工智能实践：tensorflow笔记](https://www.icourse163.org/course/PKU-1002536002)
